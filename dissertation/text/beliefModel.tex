%\chapter{Belief Model}
\section{Belief Model}
\label{sec:uavBelief}
The belief model is the fundamental piece that allows the swarm to function as a cohesive group instead of many individuals in the same local area.  The belief model consists of data about all cells in the world grid and data about all known targets.  Each UAV has its own unique belief about the current state of the world.  Periodically the UAVs broadcast their belief to everyone nearby within communications range.  When a UAV receives another UAV's belief model the receiver merges the incoming data into their own internal belief model.  By this mechanism data is shared and propagated throughout the swarm.  Therefore the communication range of each UAV is a limiting factor in the effectiveness of the swarm.  Like all team based exercises effective communication is critical to success.  Figure~\ref{fig:comm_ranges} shows the communication ranges of the blue swarm as cyan circles around the swarm members.  In this figure only the two swarm members in the bottom left have overlapping communication ranges so only those two are sharing belief data at this moment in the simulation.

%\end{multicols*}

%\begin{multicols*}{2}

%\section{Cell Beliefs}
\subsection{Cell Beliefs}
Prior to beginning the mission the geographic area is tessellated into a rectangular grid of $M$ rows and $N$ columns.  The actual physical size of the cells is irrelevant to the algorithm.  However, scanning half a cell and declaring it empty while a target sits in the other half is erroneous.  Therefore a constraint exists such that the grid cells must be small enough so that the smallest field-of-view of all the sensors must be able to completely encompass a grid cell in a single sensor frame.  This constraint prevents the noted error condition.

\begin{figure}[H]
	\centering
	%\includegraphics[width=\linewidth,height=\textheight]{imagefile}
	\includegraphics[scale=0.3]{comm_ranges.png}
	\caption{UAV communication ranges at $10\%$}
	\label{fig:comm_ranges}
\end{figure}

Each cell in the world grid is identified by a row and column index.  Each cell contains a probability of being empty, $P(empty)$, and a timestamp of when this data was last updated.  This is commonly called a Grid Based Occupancy Map. The probability value is updated in a Bayesian fashion by sensor scans during each time step of the simulation similar to~\cite{waharte}.  This probability is then used to derive a Discrete Shannon Uncertainty (also known as Shannon Entropy~\cite{shannon}) value.

A Shannon Uncertainty curve is zero when $P(empty)$ is 0\% or 100\% since in those edges cases we know for certain if the cell is empty or not.  Conversely a Shannon Uncertainty curve is at its peak when we know nothing for certain when $P(empty)$ is 50\%.  Nominally a Shannon Uncertainty curve varies from zero to one when $P(empty) = 0.5$. \textbf{TODO: multicol format issue}  The equation can be see in~\ref{eq:shannon} and is plotted in figure~\ref{fig:shannon}.

\end{multicols*}

\begin{equation}
	\label{eq:shannon}
		U = -P(empty) * \log_{2}(P(empty)) - ( 1-P(empty) * \log_{2}(1-P(empty)))
\end{equation}

\begin{multicols*}{2}

\begin{figure}[H]
	\centering
	%\includegraphics[width=\linewidth,height=\textheight]{imagefile}
	\includegraphics[scale=0.4]{shannon.png}
	\caption{Shannon Uncertainty}
	\label{fig:shannon}
\end{figure}

The goal of the mission is to destroy all the unknown targets in the search-and-destroy scenario.  Therefore the desired end state of the UAVs' shared belief model is to reduce the Shannon Uncertainty of each world cell to 0\%.  In this case all targets have been destroyed and all locations in the world have been explored.  In practice the world cells are never all driven to 0\% at once.  There is a global certainty decay rate that is applied to the cell beliefs at every time step.  It slowly drives $P(empty)$ back to 50\% over time.  This models the fact that unless a UAV is watching a cell they cannot know with 100\% certainty what is going on within that cell.  There is a chance that a moving target that has somehow evaded detection could be occupying a previously scanned world cell location.  So instead of requiring the uncertainty of all world cells to be at 0\% to end the mission we only require that all cells be driven below a user defined threshold percentage.

%\section{Target Beliefs}
\subsection{Target Beliefs}
When a UAV detects something that might be a target it adds a Target Belief to its Belief Model.  The Target Belief contains an estimation of the target's location and orientation.  It also contains a list of all possible target types and an associated probability that the detected target is the corresponding type of target. The list of target type probabilities within a Target Belief always sum up to one.  At initialization all target types are equally likely.  As time progresses and more sensor scans of the target are completed the probabilities per target type will converge to a single type.  This is accomplished with a Bayesian Inference system.  

The Bayesian Inference update equation is shown in equation~\ref{eq:bayesian} where $P_{t}(T_{i})$ is the current probability that the target's type $T$ is the $ith$ target type, $P_{t-1}(T_{i})$ is the previous timestep's probability that the target's type $T$ is the $ith$ target type, $P(T_{i}|S_{i})$ is the probability of a sensor $S$ detecting target type $i$ and correctly perceiving it as a type $i$, and $P(T_{j}|S_{i})$ is the probability of mis-perceiving a detection of a target type $i$ as a target type $j$.  This equation is applied for every suspected target type returned from a sensor scan of a world cell. After all of the sensor's possible target type results have been evaluated then the probabilities for all target types are normalized in the Target Belief.

%is the Detected Target Type from a sensor scan and $TT$ is a Target Type. $P_{TT}(x)$ is the probability that the scanned target's type is the $x$ type.  This equation is applied for every suspected target type returned from a sensor scan.  After all of the sensor's possible target type results have been evaluated then the probabilities for all target types are normalized in the Target Belief.\textbf{TODO: mulitcol format}

%	P(\text{Detected Target Type} Y) = \frac{P(detect tgt type y) * P(prev belieft tgt Y exists)}{\sum_{T_{0}}^{Num Tgts}P(detect X as Y) * P(Prev beleif of X)}
%	P(\text{Target is detected type}) = \frac{P(\text{Detecting Target Type}) * P(\text{Previous Target is detected type})}{\sum_{i=T_{0}}^{All types}d}

%P(\text{(Mis)Classifying T_{i} as detected type}) * P(\text{Previous Target is T_{i}})

%\end{multicols*}

%\begin{equation}
%\label{eq:bayesian_verbal}
%P_{TT}^{'}(DTT) = \frac{ P(\text{Detecting }TT) * P_{TT}(DTT)} {\sum_{i=0}^{\text{Target types}}P(\text{ (Mis)Classifying } i \text{ as } DTT) * P_{TT}(i)}
%\end{equation}

\begin{equation}
\label{eq:bayesian}
P_{t}(T_{i}) = \frac{P(T_{i}|S_{i})*P_{t-1}(T_{i})}{ \sum_{j=0}^{\text{All Target Types}}P(T_{j}|S_{i}) * P_{t-1}(T_{j}) }
\end{equation}


%	P_{TT}(DTT) = \frac{ P(\text{Detecting }TT) * P_{TT}(DTT)}  {ddd}


%\begin{multicols*}{2}
In addition to estimated data about the actual target, Target Beliefs encapsulate information about the tasks performed on the target.  This tasking data is collectively called the Target Task Status.  This data is used for coordinating activities within the swarm.  Since the swarm of UAVs has no centralized control system to allocate task assignments this process must be done by mutual consent within the swarm.  Each Target Belief has a Target Task Status that denotes who is performing tasks on a target and if the task is still eligible for others to take over.  The Target Task Status includes the following attributes.

\begin{description}
	\item [Monitor UAV ID] The ID of the UAV who has the best monitor score.
	\item [Monitor UAV Score] The best known score for monitoring the target.
	\item [Monitor Task State] An enumeration describing the current phase of task coordination for monitoring.
	\item [Monitor Update Timestamp] The time when the monitor data was last updated.
	\item [Attack UAV ID] The ID of the UAV who has the best attack score.
	\item [Attack UAV Score] The best known score for attacking the target.
	\item [Attack Task State] An enumeration describing the current phase of task coordination for the attack.
	\item [Attack Update Timestamp] The time when the attack data was last updated.
	\item [Target Destroyed Flag] A flag indicating if the target has been destroyed or not.
\end{description}

The Task State enumerations control when and who may bid on tasks.  There are subtle differences in their uses between the monitor tasks and the attack tasks.  These are explained in detail in  section~\ref{sec:uncoordTaskingMyWork}.

\textbf{TODO: Task state should be before Target Task Status so it's defined ahead of time.}

\begin{description}
	\item [NO TASK] This is the initial null condition given to the monitor and attack tasks.  In the monitor case it means the target was just discovered and no one has had a chance to process it.  In the attack case it means no one has confirmed that the target should be destroyed.
	\item [Open] The task is open to any and all bids.  No one has attempted to claim the task yet.
	\item [Enroute] This means the UAV with the corresponding ID is on its way to the target to perform the corresponding task.  Anyone else could overrule if they have better score than current best UAV.
	\item [Performing] The UAV with the corresponding ID is now performing the action.  No one else may overrule or otherwise subsume the action without a special exemption.%regardless of their score.
	\item [Complete] The task has been completed by the UAV with the corresponding ID.  In the monitor case the target has been confirmed as destroyed.  In the attack case a weapon has been deployed but the target is not necessarily destroyed.
\end{description}

%\section{Merging Beliefs}
\subsection{Merging Beliefs}
Each UAV in the swarm periodically broadcasts its internal Belief Model.  The model is shown in Object Diagram format in figure~\ref{fig:belief_object}.  The entire model is encoded and transmitted to all other swarm members within communications range.   When a UAV receives another swarm member's belief model it must be merged with the receiver's internal belief.  No UAV completely trusts any other UAV in the swarm.  All data is merged in a weighted or filtered fashion.  No data is copied 100\% as-is since there are no guarantees that any one UAV is perfectly correct about anything.  The mering process in this work is an implementation of the Fusion Update technique described in~\cite{shem} for merging multiple values of uncertainty.

\textbf{TODO: Multicol formatting issue}
%The entirety of the Belief Model is shown in figure~\ref{fig:belief_object} in an Object Diagram.
\end{multicols*}
\begin{figure}[H]
	\centering
	%\includegraphics[width=\linewidth,height=\textheight]{imagefile}
	\includegraphics[scale=0.75]{belief_object.png}
	\caption{Belief Model Object Diagram}
	\label{fig:belief_object}
\end{figure}
\begin{multicols*}{2}

%\textbf{TODO: Future work: Sensor type expertise should weigh into this}.

Merging Cell Beliefs is a simple process and is described in algorithm~\ref{alg:mergeCell} in section~\ref{sec:algorithms}.   In short the receiving UAV compares every single world cell with its counterpart in the sending UAV's data.  If the last update timestamp of the incoming cell data is more recent than the currently stored data then the cell data is merged.  The merge process is a weighted average.  When the merge occurs the receiving UAV's timestamp is set to the timestamp of sending UAV's data.  This prevents future belief broadcasts from the same sending UAV to trigger another re-merging of the exact same cell data.  This also prevents the same data from re-merging if a third party UAV forwards the belief data. \textbf{TODO: "Alpha filter used because of timestamps, can't rely solely on uncertainty." Your approach of merging based on a user selected weighting doesn’t make any Bayesian sense. I haven’t looked into the actual math to see if there is a precise Bayesian formulation that could be easily applied. I’ve thought through a couple of simple approaches and probably the one that makes the most sense is to simply select the value with the least uncertainty. This value has to be the result of more information than was available to the other UAV (the only way to have lower uncertainty is through more sensor readings, or readings from a better sensor). }

Table~\ref{tab:exampleCellMerge} shows an example of merging a single cell.  At some time in the simulation UAV 1 believes cell $[2, 6]$ has a 20\% of being empty (or in other words an 80\% chance that something is there). This probability was last updated at time 1234.  UAV 1 has broadcasted this belief data and UAV 2 has received it.  UAV 2 believes there is a 50\% chance that the same cell is empty but this data was last updated a long time ago at time 22.  Therefore UAV 2 will merge UAV 1's data for this cell.  Since alpha is set to 0.6 the new $P_{2,6}(empty)$ for UAV 2 is $0.6*(0.2) + (1-0.6)*(0.5)=0.32$.  After the merging is complete UAV 2's $P(empty)$ value is set to $0.32$ and the last update timestamp is set to UAV 1's timestamp.

\begin{table}[H]
	\caption{Example cell merging with $alpha=0.6$}
	\centering
	\rowcolors{1}{lightgray}{white}
	\label{tab:exampleCellMerge}
	\begin{tabular}{|r|c|c||c|c|}
		\hline
		                & \multicolumn{2}{c||}{Before Merge} & \multicolumn{2}{c|}{After Merge} \\
		\hline
		UAV             & 1   & 2                            & 1   & 2 \\
		\hline
		$P_{2,6}(empty)$& 0.2 & 0.5                          & 0.2 & 0.32 \\
		\hline
		Timestamp       & 1234& 22                           & 1234& 1234 \\
		\hline
	\end{tabular}
\end{table}

Merging Target Beliefs is more complicated but uses a similar weighted averaging technique as merging Cell Beliefs.  The model in this paper assumes that the UAVs are able to perform target track fusion (also known has cross-track correlation) amongst themselves and assign each track a unique ID such as in~\cite{stroupe}, \cite{barooah}, and~\cite{spillings}.  This process is outside the scope of this paper.

As stated earlier Target Beliefs have an estimated location, orientation, and list of target type probabilities.  Now we assume they also have a unique identifier assigned by the target track fusion process.  This unique identifier is used as a first pass comparison filter when merging Target Belief data.  If the receiving UAV does not have any data for the incoming Target Belief it simply copies it verbatim.  If the receiving UAV already has data for the Target Belief then a more detailed inspection is required.  Target Beliefs only get merged if the received data is newer than the currently stored data.  In this case the estimated target orientation, position, and list of type probabilities are all averaged with a user defined weighting against the incoming data.  The formal algorithm is defined in algorithm~\ref{alg:mergeTarget}.

The Target Task Status within a Target Belief is also merged with incoming data.  Instead of performing weighted averages logic must be applied to determine if the task status data is still live and active or if the data is transmitted for historical reference only.  The formal algorithm is defined in algorithm~\ref{alg:mergeTaskStatus} of section~\ref{sec:algorithms}.
