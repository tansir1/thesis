\chapter{UAV Model}
Each UAV within the simulation is a self contained entity capable of acting and thinking on its own accord.  No UAV requires the presence of any other UAV or the aid of any external actor.  The swarm is made of multiple independent UAVs that share information and in doing so coordinate actions to complete the mission.  The simulation supports an arbitrary number of user defined UAV types (or platforms).

\todo{Mention each type has user defined payload}

\section{UAV Kinematics}
Each UAV type has a fixed speed and turning radius.  The fixed speed represents the aircraft's standard cruising speed that it will maintain throughout the simulation.  An example set of UAV type kinematic configuration data is shown in table~\ref{tab:uavKinematic}.

\begin{table}[h]
	\caption{UAV kinematic definitions}
	\centering
	\rowcolors{1}{lightgray}{white}
	\label{tab:uavKinematic}
	\begin{tabular}{|p{1cm}|p{2cm}|p{1cm}|}
		\hline
		UAV Type & Turning Radius (m) & Speed ($\frac{m}{s}$)\\ \hline
		0 & 300 & 30 \\
		1 & 150 & 50 \\
		\hline
	\end{tabular}
\end{table}

UAVs know their current 2D coordinate and heading.  This information is used to compute a path to any destination location and orientation.  In formal mathematics terms the kinematic model of a UAV is defined as \dots

\begin{align}
\dot{x} &= v \cos(\psi) \label{eq:uavChngX}\\
\dot{y} &= v \sin(\psi) \label{eq:uavChngY}\\
\dot{\psi} &= \{-constant, 0, constant\} \label{eq:uavTurnRate}\\
\dot{v} &= 0 \label{eq:uavAccel}\\
\psi_{constant} &= \frac{v*\sin(\pi)}{r} \label{eq:uavTurnRateDeriv}
\end{align}

\dots where $x$ and $y$ represent the UAV's current position on a Cartesian plane, $v$ is the UAV's fixed speed, $\psi$ is the UAV's heading, and $r$ is the UAV's turning radius.  Equations~\ref{eq:uavChngX} and \ref{eq:uavChngY} enforce that a UAV's position changes relative to its speed on a continuous trajectory.  Equation~\ref{eq:uavTurnRate} forces the UAVs to always turn at a known rate or not at all.  This allows for simplified trajectory planning using the equations for Dubin's Path described in section~\ref{sec:dubin}.  Equation~\ref{eq:uavAccel} states that the UAVs move at a constant speed.  The constant for the turn rate is computed as shown in equation~\ref{eq:uavTurnRateDeriv}.






\section{UAV Tasks}
UAV's compete to selectively perform tasks in order to complete the mission.  The available tasks are \textit{Search}, \textit{Monitor}, and \textit{Attack}.  The Search task is always available for all UAVs to carry out.  The Monitor and Attack tasks are can only be executed in association with a suspected or confirmed target.\todo{Explain assignment states here?}

\subsection{Search}\todo{Uncertainty first used here but not defined}
No target locations within the simulated world are known \textit{a priori}.  The UAV's must discover all targets individually.  This was accomplished by mimicking the foraging behaviors of animals with an algorithm similar in principle to a \textit{L\'evy Flight} but adapted to a discrete world instead of a continuous world. \todo{Cite levy flight papers}  The UAV foraging algorithm is enumerated in algorithm~\ref{alg:forage} in appendix~\ref{sec:algorithms}.  The algorithm will randomly select a grid cell within the world or it will divide the world into kernels, compute the uncertainty of each kernel, and randomly select a cell within the most uncertain kernel.  The kernel size must divide equally into the number of rows and columns in the world.

%https://en.wikipedia.org/wiki/L%C3%A9vy_flight

Once a search cell has been selected the UAV will fly towards it until another task takes precedence or the uncertainty in the cell falls below a user configured threshold.  The uncertainty in the cell changes when the UAV's sensors can reach it and when an update from another UAV in the swarm provides new data about the cell. If the uncertainty in the cell drops below the user configured threshold then the UAV will select a new cell to investigate.  Given that the UAV is within the most uncertain kernel when the selected cell becomes certain it will search another nearby cell.  Typically the UAV will search neighboring cells until the local kernel becomes more certain than other kernels in the world.  An atypical case occurs when the UAV selects a completely random location in the world.  The weighting between searching a kernel area versus random world locations is controlled by the $randomWeighting$ parameter in algorithm~\ref{alg:forage}.

While performing the search task UAV's point their sensor payloads towards the selected search cell even if they are not within range.  While traversing the world the UAV will opportunistically scan all cells encompassed by the sensor's field of view.


\subsection{Monitor}
The Monitor task requires a UAV to watch a potential target.  The UAV will point its sensing payloads at the target, confirm the target's identity, track the target, and perform a battle damage assessment after the target has been struck.  These steps are broken down into states within the Monitor task.  The monitor task state transitions are illustrated in figure~\ref{fig:monitor}. \todo{Need a page or section here?} 
\todo{Image formatting}

\begin{figure}[p]
	\centering
	%\includegraphics[width=\linewidth,height=\textheight]{imagefile}
	\includegraphics[scale=0.5]{uav_monitor_states.png}
%	\includegraphics{uav_monitor_states.png}
	\caption{Monitor sub-states}
	\label{fig:monitor}
\end{figure}

\subsubsection{En Route}
When a UAV first starts the Monitor task it begins flying towards the target and points its payloads in the target's direction.  As the UAV flies it continues to scan any cell within its payload's field of view until the target is within range.  Once the target is in sensor range the UAV transitions to the Target Confirmation state.  

When the UAV is in sensor range it will begin orbiting the target.  If the target moves more than some user configurable percentage of the sensor's range then the UAV will adjust it's flight path and recenter the orbit over the target's new location.

\subsubsection{Target Confirmation}
When the target is within sensor range the UAV will focus its sensors on the target.  This causes the sensors to stop performing a wide area scan and to zoom in on the target's suspected world cell location.  At this time the UAV is analyzing the sensor data to determine if the suspected target is a real target or if it's a false positive and no target exists.  No other targets can be detected in during this focused scan.  If the suspected target is fake then the UAV exits the Monitor task.  If the target is confirmed to be real then the UAV transitions to the Track Target state.  For purposes of this experiment the target confirmation analysis process was assumed to take 10 seconds.  No attempt was made to model real world physics of target identification from raw sensor data.

\subsubsection{Track Target}
In this state the UAV is continuing to point its payloads at the target but the sensors have resumed a wide area scan in hopes of finding other nearby targets.  The UAV stays in this state until the target outruns the UAV's sensors and is lost or the target is struck by a weapon.  When the UAV first enters this state it requests a weapon's strike on the target from the swarm.  The details of the weapon's strike request are presented in section~\ref{sec:uavBelief}.

\subsubsection{Battle Damage Assessment}
When the monitoring UAV detects a weapon's strike on the target it will transition from wide area scan tracking to narrow focused scans of the target's location.  As in the Target Confirmation state during this focused scan no other targets can be detected and the certainty of other cells do not change.  This state represents the time it takes for the UAV to analyze its sensor data to determine if the target was destroyed or if it is still active.  Again, for purposes of the experiment it was assumed that battle damage assessment (BDA) takes 10 seconds to complete.  No attempt was made to model real world physics of target status from raw sensor data.

If the target is still active after the weapon's strike the UAV will transition back to the Track Target state and request another strike from the swarm.  If the target was destroyed then the UAV will exit the Monitor task.


\subsection{Attack}
The Attack task mechanics are similar to the Monitor task in that the UAV will fly towards the target and point all of its sensors at the target.  The UAV will plot a course such that its heading is aligned with the best attack angle relative to the heading of the target.  The UAV will re-plot a new course if the target moves a significant distance.  This distance is user configurable.  The UAV will wait until the distance to the target is below some percentage of the weapon's max range before firing.  For purposes of this experiment the percentage was set to 80\%.

The weapon time-of-flight is not modeled.  Weapon strikes are considered instantaneous.  When the weapon is deployed the UAV has completed the task.  The UAV may assign itself a new task and begin maneuvering to a new destination.  However, the UAV performing the Monitor task may request another weapon strike from the swarm if the target was not destroyed.  Therefore the UAV that completed the Attack task might decide to perform it again since it's likely the closest strike platform available.  The details of this process are explained in section~\ref{XXXX}.\todo{Fix reference.} 


\section{Belief Model}
\label{sec:uavBelief}
The belief model is the fundamental piece that allows the swarm to function as a cohesive group instead of many individuals in the same local area.  The belief model consists of data about all cells in the world grid and data about all known targets.  Each UAV has its own unique belief about the current state of the world.  Periodically the UAVs broadcast their belief to everyone nearby within communications range.  When a UAV receives another UAV's belief model the receiver merges the incoming data into their own internal belief model.  By this mechanism data is shared and propagated throughout the swarm.  Therefore the communication range of each UAV is a limiting factor in the effectiveness of the swarm.  Like all team based exercises effective communication is critical to success.\todo{Add graphic of comm ranges}  

\subsection{Cell Beliefs}\todo{Image of cell attributes}
Prior to beginning the mission the geographic area is tessellated into a rectangular grid of $M$ rows and $N$ columns.  The actual physical size of the cells is irrelevant to the algorithm.  However, scanning half a cell and declaring it empty while a target sits in the other half is erroneous.  Therefore a constraint exists such that the grid cells must be small enough so that the smallest field-of-view of all the sensors must be able to completely encompass a grid cell in a single sensor frame.  This constraint prevents the noted error condition.

Each cell in the world grid is identified by a row and column index.  Each cell contains a probability of being empty ($P(empty)$) and a timestamp of when this data was last updated.  The probability value is updated in a Bayesian fashion by sensor scans \todo{Explain this process}during each time step of the simulation.  This probability is then used to derive a Discrete Shannon Uncertainty (also known as Shannon Entropy) value\todo{Cite shannon paper}.  A Shannon Uncertainty curve is zero when $P(empty)$ is 0\% or 100\% since in those edges cases we know for certain if the cell is empty or not.  Conversely a Shannon Uncertainty curve is at its peak when we know nothing for certain when $P(empty)$ is 50\%.  Nominally a Shannon Uncertainty curve varies from zero to roughly 0.301 (when $P(empty) = 0.5$).  The equation can be see in~\ref{eq:shannon}.  For ease of use it can be scaled from zero to one by dividing~\ref{eq:shannon} by it's maximum value of $U_{max}$ shown in~\ref{eq:shannon_max}.  The results of this are plotted in figure~\ref{fig:shannon}.

\begin{equation}
	\label{eq:shannon}
	\begin{split}
		U = & -P(empty) * \log_{10}(P(empty)) \\
            & - ( 1-P(empty) * \log_{10}(1-P(empty)))
	\end{split}
\end{equation}

\begin{equation}
	\label{eq:shannon_max}
	\begin{split}
		U_{max} = & -0.5 * \log_{10}(0.5) \\
		          & - (0.5 * \log_{10}(0.5)) \\
		          & \approx 0.301
	\end{split}
\end{equation}

\begin{figure}[p]
	\centering
	%\includegraphics[width=\linewidth,height=\textheight]{imagefile}
	\includegraphics[scale=0.5]{shannon.png}
	\caption{Shannon Uncertainty}
	\label{fig:shannon}
\end{figure}

The goal of the mission is to destroy all the unknown targets in the search-and-destroy scenario.  Therefore the desired end state of the UAVs' shared belief model is to reduce the Shannon Uncertainty of each world cell to 0\%.  In this case all targets have been found and all locations in the world have been explored.  In practice the world cells are never all driven to 0\% at once.  There is a global certainty decay rate that is applied to the cell beliefs at every time step.  It slowly drives $P(empty)$ back to 50\% over time.  This models the fact that unless a UAV is watching a cell they cannot know with 100\% certainty what is going on within that cell.  There is a chance that a moving target that has somehow evaded detection and could be occupying a previously scanned world cell location.  So instead of requiring the uncertainty of all world cells to be at 0\% to end the mission we only require that all cells be driven below a user defined threshold percentage.

\subsection{Target Beliefs}
When a UAV detects something that might be a target it adds a Target Belief to its Belief Model.  The Target Belief contains an estimation of the target's location and orientation.  It also contains a list of all possible target types and an associated probability that the detected target is the corresponding type of target. The list of target type probabilities within a Target Belief always sum up to one.  At initialization all target types are equally likely.  As time progresses and more sensor scans of the target are completed the probabilities per target type will converge to a single type.  This is accomplished with the Bayesian update model described in XXX.\todo{Explain sensor bayesian process}  

In addition to estimated data about the actual target Target Beliefs encapsulate information about the tasks performed on the target.  This data is used for coordinating activities within the swarm and is described in detail in section~\ref{sec:uncoordTasking}.

\subsection{Merging Beliefs}
Each UAV in the swarm periodically broadcasts its internal Belief Model.  The entire model is encoded and transmitted to all other swarm members within communications range.  When a UAV receives another swarm member's belief model it must be merged with the receiver's internal belief.  No UAV completely trusts any other UAV in the swarm.  All data is merged in a weighted or filtered fashion.  No data is copied 100\% as-is since there are no guarantees that any one UAV is perfectly correct about anything.

Merging Cell Beliefs is a simple process.  The formal algorithm can be found in~\ref{alg:mergeCell}.  In short the receiving UAV compares every single world cell with its counterpart in the sending UAV's data.  If the last update timestamp of the incoming cell data is more recent than the currently stored data then the cell data is merged.  The merge process is a weighted average.  When the merge occurs the receiving UAV's timestamp is set to the timestamp of sending UAV's data.  This prevents future belief broadcasts from the same sending UAV to trigger another re-merging of the exact same cell data.  This also prevents the same data from re-merging if a third party UAV forwards the belief data. 

Table~\ref{tab:exampleCellMerge} shows an example of merging a single cell.  At some time in the simulation UAV 1 believes cell $[2, 6]$ has a 20\% of being empty (or in other words an 80\% chance that something is there). This probability was last updated at time 1234.  UAV 1 has broadcasted this belief data and UAV 2 has received it.  UAV 2 believes there is a 50\% chance that the same cell is empty but this data was last updated a long time ago.  Therefore UAV 2 will merge UAV 1's data for this cell.  Since alpha is set to 0.6 the new $P_{2,6}(empty)$ for UAV 2 is $0.6*(0.2) + (1-0.6)*(0.5)=0.32$.  After the merging is complete UAV 2's $P(empty)$ value is set to $0.32$ and the last update timestamp is set to UAV 1's timestamp.

\begin{table}[h]
	\caption{Example cell merging with $alpha=0.6$}
	\centering
	\rowcolors{1}{lightgray}{white}
	\label{tab:exampleCellMerge}
	\begin{tabular}{|r|c|c||c|c|}
		\hline
		                & \multicolumn{2}{c||}{Before Merge} & \multicolumn{2}{c|}{After Merge} \\
		\hline
		UAV             & 1   & 2                            & 1   & 2 \\
		\hline
		$P_{2,6}(empty)$& 0.2 & 0.5                          & 0.2 & 0.32 \\
		\hline
		Timestamp       & 1234& 22                           & 1234& 1234 \\
		\hline
	\end{tabular}
\end{table}

Merging Target Beliefs is more complicated but uses a similar weighted averaging technique as merging Cell Beliefs.  The model in this paper assumes that the UAV's are able to perform target track fusion amongst themselves and assign each track a unique ID.  This process is outside the scope of this paper.

As stated earlier Target Beliefs have an estimated location, orientation, and list of target type probabilities.  Now we assume they also have a unique identifier assigned by the target track fusion process.  This unique identifier is used as a first pass comparison filter when merging Target Belief data.  If the receiving UAV does not have any data for the incoming Target Belief it simply copies it verbatim.

\section{Uncoordinated Tasking}
\label{sec:uncoordTasking}
foo foo foo

limited comms range

\begin{table}[h]
	\caption{UAV sensor payload configuration}
	\centering
	\rowcolors{1}{lightgray}{white}
	\label{tab:uavSensorMap}
	\begin{tabular}{|p{1cm}|p{1cm}|p{1cm}|}
		\hline
		UAV Type & Sensor Type\\ \hline
		0 & 1 \\
		1 & 0 \\
		\hline
	\end{tabular}
\end{table}


\todo{Insert sim data for weapon numbers}
\begin{table}[h]
	\caption{UAV weapon payload configuration}
	\centering
	\rowcolors{1}{lightgray}{white}
	\label{tab:uavWpnMap}
	\begin{tabular}{|p{1cm}|p{1.5cm}|p{2cm}|}
		\hline
		UAV Type & Weapon Type & Initial Quantity\\ \hline
		0 & 0 & 2 \\
		0 & 1 & 2 \\
		1 & 0 & 5 \\
		1 & 1 & 5 \\
		\hline
	\end{tabular}
\end{table}
